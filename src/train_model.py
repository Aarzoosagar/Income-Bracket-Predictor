# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fCrGRXLyhs1yAoPUCajElkN2f3T2P6KP
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
import joblib

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
cols = [
    "age", "workclass", "fnlwgt", "education", "education-num",
    "marital-status", "occupation", "relationship", "race", "sex",
    "capital-gain", "capital-loss", "hours-per-week", "native-country", "income"
]

df = pd.read_csv(url, header=None, names=cols, na_values=" ?")
df.head()

# Drop missing values
df.dropna(inplace=True)

# Strip whitespace
for c in df.select_dtypes(include='object').columns:
    df[c] = df[c].str.strip()

# Convert target to binary
df['income'] = df['income'].replace({'<=50K': 0, '>50K': 1})

# Drop unneeded columns
df = df.drop(columns=['fnlwgt'])

X = df.drop('income', axis=1)
y = df['income']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()

from sklearn.impute import SimpleImputer

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])

X_train_t = preprocessor.fit_transform(X_train)
X_val_t = preprocessor.transform(X_val)
X_test_t = preprocessor.transform(X_test)

# Save the preprocessor
joblib.dump(preprocessor, "preprocessor.joblib")

input_dim = X_train_t.shape[1]

model = models.Sequential([
    layers.Input(shape=(input_dim,)),
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.25),
    layers.Dense(64, activation="relu"),
    layers.Dropout(0.2),
    layers.Dense(32, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
model.summary()

cb_early = callbacks.EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
cb_chk = callbacks.ModelCheckpoint("best_model.h5", monitor="val_loss", save_best_only=True)

history = model.fit(
    X_train_t, y_train,
    validation_data=(X_val_t, y_val),
    epochs=30,
    batch_size=128,
    callbacks=[cb_early, cb_chk],
    verbose=2
)

loss, acc = model.evaluate(X_test_t, y_test, verbose=0)
print(f"Test Accuracy: {acc:.4f}")

y_pred_prob = model.predict(X_test_t).ravel()
y_pred = (y_pred_prob >= 0.5).astype(int)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

model.save("saved_model/income_model.keras")
print("✅ Model saved successfully.")

import os

if not os.path.exists("saved_model"):
    os.makedirs("saved_model")

model.save("saved_model/income_model.keras")
print("✅ Model saved successfully.")